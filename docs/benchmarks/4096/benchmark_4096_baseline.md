# Benchmark Results: 4096 Context Baseline

- **Date**: 2026-02-15 04:13 (Local Time)
- **Model**: Qwen2.5-72B-Instruct-GPTQ-Int8
- **Engine**: vLLM V1
- **Hardware**: 8x RTX 3060 (PCIe 1x), 16GB RAM, 128GB Swap

## ğŸ“Š Performance Summary

| Test Category | TTFT (s) | Throughput (Tokens/s) | Total Time (s) | Total Tokens |
| :--- | :--- | :--- | :--- | :--- |
| **Short** | 1.28 | 12.70 | 5.29 | 51 |
| **Medium** | 1.36 | 12.19 | 22.53 | 258 |
| **Thai-Test** | 1.54 | 11.93 | 44.39 | 511 |
| **Extreme-Fiction** | 2.69 | 11.22 | 350.05 | 3899 |
<<<<<<< HEAD
=======
 
## â±ï¸ Startup & Preparation Time (Estimated)
- **Start Time**: ~03:35 (Baseline run)
- **Ready Time**: ~04:13 (Application Startup Complete)
- **Total Startup Duration**: **~35-40 à¸™à¸²à¸—à¸µ**
    - *Model Shard Loading*: ~20-25 à¸™à¸²à¸—à¸µ
    - *Graph Capture & Memory Allocation*: ~10-15 à¸™à¸²à¸—à¸µ

*\*4096 à¹ƒà¸Šà¹‰à¹€à¸§à¸¥à¸²à¹€à¸•à¸£à¸µà¸¢à¸¡ Graph à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² 8192 à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¹ƒà¸Šà¹‰ VRAM à¸™à¹‰à¸­à¸¢à¸à¸§à¹ˆà¸²à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸«à¹‡à¸™à¹„à¸”à¹‰à¸Šà¸±à¸”*
>>>>>>> experiment/8192-context

## âš™ï¸ System Metrics (Idle during Start)
- **RAM Used**: ~13GB (Including Swap usage)
- **CPU Load**: High (Busy-waiting is active)

## ğŸ“ Observations
- The **V1 Engine** delivers exceptionally high throughput (~12 TPS) even on PCIe 1x risers once generation begins.
- **Latency (TTFT)** is very manageable at under 1.6s.
- This serves as the stable baseline before testing the **8192 context** expansion.

## ğŸ“ Files
- **Story**: [cat_domination_story_4096.txt](file:///home/seiya/projects/vllm/docs/benchmarks/4096/cat_domination_story_4096.txt)
